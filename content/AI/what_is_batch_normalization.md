Title: What is Batch Normalization?  <!-- pylint: disable=markdownlint -->
Status: draft
date: 2024-08-16 10:16


Batch Normalization is a regularization technique used to improve the training of deep neural networks by normalizing the inputs to each layer. It helps to reduce phenomenon called *internal covariate shift*. What is *internal covariate shift*?

### What are the benefits of the Batch Normalization


### Where to apply the Batch Normalization?


Link to paper: https://arxiv.org/pdf/1502.03167


Thanks for Sam and others for review and feedback
